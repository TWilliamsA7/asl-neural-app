{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3d31e4",
   "metadata": {},
   "source": [
    "# ASL Neural Network Pipeline Notebook\n",
    "\n",
    "This notebook contains all the steps necessary to train a neural network for the ASL Neural Network App project located at [this repository](https://github.com/TWilliamsA7/asl-neural-app/tree/main). Utility functions can also be found in the above repository under the src directory.\n",
    "\n",
    "1. Setup: Configuration & Authentication\n",
    "2. Environment: Initialization & Imports\n",
    "3. Data: Acquisition & Preprocessing\n",
    "4. Data: Loading & Splitting\n",
    "5. Model: Architecture\n",
    "6. Model: Training\n",
    "7. Model: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc88ffa",
   "metadata": {},
   "source": [
    "## Setup: Configuration & Authenticatioon\n",
    "\n",
    "This section of the notebook is for setting up the necessary authentication and configuration of the Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c745b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for setup\n",
    "\n",
    "from google.colab import userdata, auth\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bde30",
   "metadata": {},
   "source": [
    "### Create github connection via colab variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7289b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define repository details\n",
    "USERNAME = \"TWilliamsA7\"\n",
    "REPO_NAME = \"asl-neural-app.git\"\n",
    "BRANCH_NAME = \"main\"\n",
    "\n",
    "# Get PAT (Personal Access Token) stored in Colab Secrets\n",
    "PAT = userdata.get(\"GITHUB_PAT\")\n",
    "if not PAT:\n",
    "    raise ValueError(\"GITHUB_PAT secret not found!\")\n",
    "\n",
    "# Construct Authetnicated URL for accessing repositry\n",
    "AUTHENTICATED_URL = f\"https://{PAT}@github.com/{USERNAME}/{REPO_NAME}\"\n",
    "REPO_FOLDER = REPO_NAME.replace(\".git\", \"\")\n",
    "\n",
    "# Set golabl Git configuration\n",
    "!git config --global user.email \"twilliamsa776@gmail.com\"\n",
    "!git config --global user.name \"{USERNAME}\"\n",
    "\n",
    "print(\"Setup github connection and authenticated url successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d89e6",
   "metadata": {},
   "source": [
    "### Google Cloud Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- GCS Authentication ---\")\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "print(\"Google Cloud authentication complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10250879",
   "metadata": {},
   "source": [
    "## Environment: Initialization and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5f491",
   "metadata": {},
   "source": [
    "### Clone Github Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up any existing clone (optional, but good for reliable restarts)\n",
    "if os.path.isdir(REPO_FOLDER):\n",
    "    print(f\"Removing old {REPO_FOLDER} folder...\")\n",
    "    !rm -rf {REPO_FOLDER}\n",
    "\n",
    "# Clone the repository using the authenticated URL\n",
    "print(f\"Cloning repository: {REPO_NAME}...\")\n",
    "!git clone {AUTHENTICATED_URL}\n",
    "\n",
    "# Change directory into the cloned repository\n",
    "%cd {REPO_FOLDER}\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e3b2f",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "- Includes manual inclusion of kaggle.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e364e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing project dependencies...\")\n",
    "\n",
    "# Use pip to install everything in your requirements.txt\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "print(\"Dependencies installed successfully.\")\n",
    "\n",
    "# Install Kaggle API\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "# --- IMPORTANT: Manually upload kaggle.json to the ~/.kaggle folder now ---\n",
    "print(\"\\n--- MANUAL STEP REQUIRED ---\")\n",
    "print(\"1. Click the Folder icon (left sidebar).\")\n",
    "print(\"2. Navigate to the root folder (click the / symbol).\")\n",
    "print(\"3. Navigate to the hidden folder: .kaggle\")\n",
    "print(\"4. Upload your 'kaggle.json' file into the .kaggle folder.\")\n",
    "print(\"Proceed only after kaggle.json is uploaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773ce51",
   "metadata": {},
   "source": [
    "### Connect Src directory for access to utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15926923",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src')\n",
    "print(\"Setup Complete. Colab environment is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389e19f",
   "metadata": {},
   "source": [
    "## Data: Acquisition & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339e4f8",
   "metadata": {},
   "source": [
    "### Include necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d219f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# If earlier cells are not ran\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure src accessibility\n",
    "sys.path.append('src')\n",
    "\n",
    "# Import utility functions\n",
    "from data_utils import extract_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112699ad",
   "metadata": {},
   "source": [
    "### Setup directories and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_DATASET_ID = \"grassknoted/asl-alphabet\" \n",
    "DESTINATION_PATH = \"sample_data\"\n",
    "PROCESSED_OUTPUT_DIR = 'processed_data'\n",
    "DATA_ROOT_FOLDER_NAME = 'asl_alphabet_train'\n",
    "\n",
    "os.makedirs(DESTINATION_PATH, exist_ok=True)\n",
    "os.makedirs(PROCESSED_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1419d35",
   "metadata": {},
   "source": [
    "### Download Data via Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Downloading dataset: {KAGGLE_DATASET_ID}\")\n",
    "!kaggle datasets download -d {KAGGLE_DATASET_ID} -p {DESTINATION_PATH} --unzip\n",
    "\n",
    "# Define the exact root path to the image subfolders (A, B, C, etc.)\n",
    "DATA_ROOT = os.path.join(DESTINATION_PATH, DATA_ROOT_FOLDER_NAME)\n",
    "print(f\"Image data root set to: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109baddd",
   "metadata": {},
   "source": [
    "### Feature Extraction and Array Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c994b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_BUCKET_NAME = \"gs://asl-keypoint-data-storage-2025\" \n",
    "GCS_DESTINATION_FOLDER = \"processed_features_v1\"\n",
    "\n",
    "def create_and_save_features():\n",
    "    X_keypoints, X_cnn, y_labels = [], [], []\n",
    "    \n",
    "    # Iterate through all class folders\n",
    "    for label_index, class_name in enumerate(sorted(os.listdir(DATA_ROOT))):\n",
    "        class_path = os.path.join(DATA_ROOT, class_name)\n",
    "        if not os.path.isdir(class_path) or class_name.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing Class: {class_name} (Label: {label_index})\")\n",
    "        \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            \n",
    "            # Use the imported modular function\n",
    "            keypoints, resized_img = extract_keypoints(image_path)\n",
    "            \n",
    "            if keypoints is not None:\n",
    "                # Store keypoints\n",
    "                X_keypoints.append(keypoints)\n",
    "                # Normalize and store CNN image data\n",
    "                X_cnn.append(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB) / 255.0) \n",
    "                y_labels.append(label_index)\n",
    "\n",
    "    # Convert to final NumPy arrays\n",
    "    X_keypoints_array = np.array(X_keypoints, dtype=np.float32)\n",
    "    X_cnn_array = np.array(X_cnn, dtype=np.float32)\n",
    "    y_labels_array = np.array(y_labels, dtype=np.int32)\n",
    "\n",
    "    TEMP_DIR = 'temp_feature_dump'\n",
    "    os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "    # Save the processed data to the designated output folder\n",
    "    np.save(os.path.join(TEMP_DIR, 'X_keypoints.npy'), X_keypoints_array)\n",
    "    np.save(os.path.join(TEMP_DIR, 'X_cnn_images.npy'), X_cnn_array)\n",
    "    np.save(os.path.join(TEMP_DIR, 'y_labels.npy'), y_labels_array)\n",
    "    \n",
    "    # Source is the local temp directory. Destination is the GCS path.\n",
    "    GCS_PATH = f\"{GCS_BUCKET_NAME}/{GCS_DESTINATION_FOLDER}\"\n",
    "    print(f\"\\nUploading processed features to {GCS_PATH}...\")\n",
    "    \n",
    "    # The -m flag runs the command multi-threaded (faster) and -r copies the directory recursively\n",
    "    !gsutil -m cp -r {TEMP_DIR} {GCS_PATH}\n",
    "    \n",
    "    print(\"\\nUpload to GCS complete. Features are ready for training notebook.\")\n",
    "\n",
    "    print(f\"\\nSuccessfully processed {len(X_keypoints)} samples.\")\n",
    "    print(f\"Keypoints Shape: {X_keypoints_array.shape}, Images Shape: {X_cnn_array.shape}\")\n",
    "    print(\"All processed arrays saved to the 'processed_data' directory.\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "create_and_save_features()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
